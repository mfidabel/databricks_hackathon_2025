{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cf2e052-9c92-44bd-83f9-68ca40b3499b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Get Started with Data for Good Datasets\n",
    "\n",
    "This guide assumes you have already followed the steps [here](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#1-set-up-your-workspace-and-get-data) to set up your workspace and send your Delta Sharing ID to request the partner data. It might take some time for the data to show up in the Delta Sharing section of your workspace. Once it is there, [add it as a catalog so you can use it in your workspace](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#accessing-the-data).\n",
    "\n",
    "You will have access to three schemas:\n",
    "- `bright_initiative`\n",
    "- `mimilabs`\n",
    "- `nimble`\n",
    "\n",
    "with the data provided by each of these organizations.\n",
    "\n",
    "## How to Use This Guide\n",
    "The goal of this guide is to help you with the first steps of accessing these data and using them with AI tools. Your actual projects will most likely not look like these examples, but we hope showing how to start working with the data will help you get started!\n",
    "\n",
    "## Recommended Approach\n",
    "1. Follow the instruction [here](https://github.com/databricks-solutions/dais-2025-genai-hackathon?tab=readme-ov-file#1-set-up-your-workspace-and-get-data) to set up your workspace and get the data.\n",
    "2. Pick a theme or challenge you are interested in.\n",
    "3. Spend some time [exploring the data](#exploring-the-data) with AI/BI Genie spaces.\n",
    "4. Determine what your application needs to do with the data in order to solve the challenge you have chosen to pursue.\n",
    "5. Pick the framework or tools that are the best fit for your application.\n",
    "6. Build!\n",
    "\n",
    "## Exploring the Data\n",
    "\n",
    "To start exploring the data, we recommend creating one or more [AI/BI Genie Spaces](https://docs.databricks.com/aws/en/genie). Genie spaces let you ask natural language questions about the data you're interested in and get SQL queries, answers, and visualizations in return. It is a great way to quickly get up to speed on new data. You can access AI/BI Genie in the left sidebar in the `SQL` section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8df0bbbd-4993-4819-9b4f-c25e3b710d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Quickstart Code Snippets\n",
    "\n",
    "Here are some short code snippets showing how to start using the data once you've added the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b30b8581-b220-455c-999f-d6639d55cfbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5867220f-0e13-42e1-b6b4-5959c67ffb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq langchain_core langchain_databricks langchain_community\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa4f2f59-8630-40ae-bd11-9862d5ebfc28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bright Initiative\n",
    "\n",
    "The Bright Initiative has provided the following data:\n",
    "- **U.S. Google Maps Businesses Dataset - 5M Records:** Access detailed information on businesses across diverse industries in the U.S., including names, addresses, contact details, and ratings. \n",
    "- **Global Booking.com Hotel Listings Dataset: 1.6M Records:** The Booking dataset provides detailed and structured information on global accommodations, including hotel descriptions, location details, pricing, amenities, and guest reviews. It offers critical insights into property features, pricing trends, and customer preferences.\n",
    "- **Global Airbnb Properties Information Dataset: 1.6M Records:** Uncover the details of global Airbnb properties with this comprehensive dataset, providing vital information for travelers, property managers, and researchers. Access key property features such as price, images, descriptions, availability, reviews, and host details.\n",
    "\n",
    "Let's look at the Airbnb Properties Dataset. First, we'll start with a simple SQL query. You can query the datasets directly from a notebook or in the SQL Editor. Note that there are two different versions of the Bright Initiave datasets, differing mostly in whether nested columns are formatted as strings or arrays. Feel free to use whichever is more convenient for your use case.\n",
    "\n",
    "Here's how we might check the reviews of different Airbnb locations for mentions of wheelchair accessibility:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8755b0a6-aafa-4038-9e38-3589cfa576a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "\n",
    "Here is a naive approach to using these data with agents. We look for listings with reviews mentioning wheelchairs, extract a few fields with information about the listings (including reviews), and ask the model to describe the accessibility features of the listings.\n",
    "\n",
    "To expand on this approach and make it more suitable for your project, consider:\n",
    "- Letting the agent write the SQL for you, which allows it to answer flexible questions like \"are there any listings with a pool?\" without you needing to write a new query for every possible feature.\n",
    "- Combining keyword search with structured data for more powerful retrieval, so you can find reviews that mention \"spacious\" but only for listings with a guest rating above 4.8.\n",
    "- Giving your agent multiple \"tools\" to choose from, such as one function to query the Airbnb data and another to fetch live hotel prices from a different partner's API.\n",
    "- Integrate with other Bright data sources for a more holistic view of neighborhood accessibility, or for comparisons with other lodging options such as hotels.\n",
    "\n",
    "There are many tools, both from LangChain and Databricks, that can help with these steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06a27fc5-baff-441f-a0df-5300ef022b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "# configure workspace tokens\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "259b139e-cba4-4e7a-8e5e-a7c01449a929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's find plans that offer fitness benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "376442b0-4d59-4a5a-8126-932e75f70687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "Here is a simple approach to using these data in the context of the agents hackathon. To expand on this approach:\n",
    "- Using [mimibot](https://www.mimilabs.ai/mimibot), explore how these data relate to other tables provided by mimilabs, enabling you to further enrich the data\n",
    "- Explore other tools you could use that would enable more flexible retrieval than a hardcoded sql query\n",
    "- Connect to a web search tool that can enrich these data with user-friendly expalantions of benefits and what they mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d934fe69-3738-4af7-b5d4-1eeeb3f25d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "import ast\n",
    "\n",
    "@tool\n",
    "def find_airbnb_properties(required_traits: str) -> str:\n",
    "  \"\"\"\n",
    "  Finds Airbnb properties that match the specified traits.\n",
    "  Use this tool when a user asks to find properties with a specific list of traits.\n",
    "  The input must be a Python list of traits provided as a string, like: 'quiet', 'calm', self-checkin', etc.\n",
    "  For example: \"['quiet', 'calm', 'self-checkin']\"\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # The LLM often returns a string representation of a list, e.g., \"['dental', 'fitness']\".\n",
    "    # ast.literal_eval safely evaluates this string into an actual Python list.\n",
    "    traits_list = ast.literal_eval(required_traits)\n",
    "    if not isinstance(traits_list, list):\n",
    "        raise ValueError(\"Input could not be parsed into a list.\")\n",
    "  except (ValueError, SyntaxError) as e:\n",
    "    # If parsing fails, return an error message to the agent so it can retry.\n",
    "    return f\"Error: Invalid input format. Expected a string representation of a list. {e}\"\n",
    "  \n",
    "  \"\"\"\n",
    "  SELECT data.*, v.description FROM vector_search(\n",
    "  index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "  query_text => '{\", \".join(traits_list)}',\n",
    "  num_results => 100\n",
    ") v\n",
    "INNER JOIN (\n",
    "    SELECT property_id, amenities, category, ratings, available_dates FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    ") data ON v.property_id = data.property_id\n",
    "  \"\"\"\n",
    "  vector_search_query = f\"\"\"\n",
    "      SELECT url, v.description, ratings, name, price FROM vector_search(\n",
    "        index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "        query_text => '{\", \".join(traits_list)}',\n",
    "        num_results => 100\n",
    "      ) v\n",
    "      INNER JOIN (\n",
    "          SELECT property_id, amenities, category, ratings, available_dates, listing_name, listing_title, name, price, url FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    "      ) data ON v.property_id = data.property_id\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {vector_search_query}\")\n",
    "  df = spark.sql(vector_search_query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "\n",
    "# Configure workspace client for authentication\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_airbnb_properties]\n",
    "\n",
    "# This prompt template tells the agent how to reason about using tools\n",
    "# This is a standard \"ReAct\" (Reasoning + Acting) prompt\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You assist Neuro Divergent people to find acommodation in San Francisco. Try to justify every listing in your final answer. Explain why you search for traits. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent a question in natural language!\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Hi\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "467f7408-1ef8-40ae-a748-63543bfae1f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "@tool\n",
    "def find_airbnb_properties(required_traits: str) -> str:\n",
    "  \"\"\"\n",
    "  Finds Airbnb properties that match the specified traits.\n",
    "  Use this tool when a user asks to find properties with a specific list of traits.\n",
    "  The input must be a Python list of traits provided as a string, like: 'quiet', 'calm', self-checkin', etc.\n",
    "  For example: \"['quiet', 'calm', 'self-checkin']\"\n",
    "  \"\"\"\n",
    "  try:\n",
    "    # The LLM often returns a string representation of a list, e.g., \"['dental', 'fitness']\".\n",
    "    # ast.literal_eval safely evaluates this string into an actual Python list.\n",
    "    traits_list = ast.literal_eval(required_traits)\n",
    "    if not isinstance(traits_list, list):\n",
    "        raise ValueError(\"Input could not be parsed into a list.\")\n",
    "  except (ValueError, SyntaxError) as e:\n",
    "    # If parsing fails, return an error message to the agent so it can retry.\n",
    "    return f\"Error: Invalid input format. Expected a string representation of a list. {e}\"\n",
    "  \n",
    "  \"\"\"\n",
    "  SELECT data.*, v.description FROM vector_search(\n",
    "  index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "  query_text => '{\", \".join(traits_list)}',\n",
    "  num_results => 100\n",
    ") v\n",
    "INNER JOIN (\n",
    "    SELECT property_id, amenities, category, ratings, available_dates FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    ") data ON v.property_id = data.property_id\n",
    "  \"\"\"\n",
    "  vector_search_query = f\"\"\"\n",
    "      SELECT url, v.description, ratings, name, price FROM vector_search(\n",
    "        index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "        query_text => '{\", \".join(traits_list)}',\n",
    "        num_results => 100\n",
    "      ) v\n",
    "      INNER JOIN (\n",
    "          SELECT property_id, amenities, category, ratings, available_dates, listing_name, listing_title, name, price, url FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    "      ) data ON v.property_id = data.property_id\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {vector_search_query}\")\n",
    "  df = spark.sql(vector_search_query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "# Define a Python function to wrap the agent\n",
    "class LangChainAgentWrapper(mlflow.pyfunc.PythonModel):\n",
    "    @tool\n",
    "    def find_airbnb_properties(required_traits: str) -> str:\n",
    "        \"\"\"\n",
    "        Finds Airbnb properties that match the specified traits.\n",
    "        Use this tool when a user asks to find properties with a specific list of traits.\n",
    "        The input must be a Python list of traits provided as a string, like: 'quiet', 'calm', self-checkin', etc.\n",
    "        For example: \"['quiet', 'calm', 'self-checkin']\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # The LLM often returns a string representation of a list, e.g., \"['dental', 'fitness']\".\n",
    "            # ast.literal_eval safely evaluates this string into an actual Python list.\n",
    "            traits_list = ast.literal_eval(required_traits)\n",
    "            if not isinstance(traits_list, list):\n",
    "                raise ValueError(\"Input could not be parsed into a list.\")\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            # If parsing fails, return an error message to the agent so it can retry.\n",
    "            return f\"Error: Invalid input format. Expected a string representation of a list. {e}\"\n",
    "        \n",
    "        \"\"\"\n",
    "        SELECT data.*, v.description FROM vector_search(\n",
    "        index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "        query_text => '{\", \".join(traits_list)}',\n",
    "        num_results => 100\n",
    "        ) v\n",
    "        INNER JOIN (\n",
    "            SELECT property_id, amenities, category, ratings, available_dates FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    "        ) data ON v.property_id = data.property_id\n",
    "        \"\"\"\n",
    "        vector_search_query = f\"\"\"\n",
    "            SELECT url, v.description, ratings, name, price FROM vector_search(\n",
    "                index => 'neurodivergent_app.bright_initiative.airbnb_index_filtered',\n",
    "                query_text => '{\", \".join(traits_list)}',\n",
    "                num_results => 100\n",
    "            ) v\n",
    "            INNER JOIN (\n",
    "                SELECT property_id, amenities, category, ratings, available_dates, listing_name, listing_title, name, price, url FROM neurodivergent_app.bright_initiative.airbnb_properties_information_filter\n",
    "            ) data ON v.property_id = data.property_id\n",
    "        \"\"\"\n",
    "        print(f\"Executing query: {vector_search_query}\")\n",
    "        df = spark.sql(vector_search_query).toPandas()\n",
    "        return df.to_json(orient='records', indent=2)\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.agent = create_react_agent(llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=self.agent, tools=[self.find_airbnb_properties], verbose=True)\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        prompt = model_input[\"prompt\"][0]\n",
    "        return self.agent_executor.invoke({\n",
    "            \"input\": prompt\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3775efbf-3226-490f-a083-64fe09abb3a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"langchain_agent\",\n",
    "        python_model=LangChainAgentWrapper(),\n",
    "        input_example=pd.DataFrame({\"prompt\": [\"What is the capital of France?\"]}),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce3ea01-6792-456c-bedf-6d751558ed02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = \"runs:/6312a93d6ed048e88fbf5ddb3c66591e/langchain_agent\"\n",
    "uc_model_path = \"neurodivergent_app.bright_initiative.langchain_agent_model\"\n",
    "\n",
    "mlflow.register_model(model_uri=model_uri, name=uc_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68ee2998-c4bb-4e76-9422-9748bdfc58bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377aad0a-1341-49fe-be29-8655527cacbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5d613f6-4ba2-4e8c-84ee-a0ffb44e5516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Nimble\n",
    "\n",
    "See [this page](https://nimbleway.notion.site/Hackathon-Resource-Center-209c8a32950080f785e6cecc1e502a8b) for details on getting started with Nimble's MCP server and advice for using Nimble in the hackathon, and [this notebook](https://github.com/databricks-solutions/dais-2025-genai-hackathon/blob/main/2025_agent_hackathon_resources/nimble-mcp.ipynb) for instructions on using Nimble's MCP server with Databricks model serving via LangGraph and/or LlamaIndex.\n",
    "\n",
    "The Nimble team has also provided access to structured data from a variety of sources, such as amazon, footlocker, walmart, and yelp.\n",
    "\n",
    "Here's an example of working with the Amazon product data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f304927-0d60-4927-bf68-e55800a45c83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Integrate with Agents\n",
    "\n",
    "Here is a simple way to set up an agent to come up with multiple search terms and query the amazon products table for products to solve a given problem. To extend this for your hackathon project, you could:\n",
    "- Follow the links to get more information on the specific Amazon products\n",
    "- Obtain additional data sources using the Nimble MCP server\n",
    "- Use a multimodal model to evaluate the product images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eab4d73-2d5f-44c7-ad00-8693e7a63efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.tools import tool\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "\n",
    "@tool\n",
    "def find_products_by_keyword(search_term: str) -> str:\n",
    "  \"\"\"\n",
    "  Searches the Nimble e-commerce dataset for products matching a keyword search_term.\n",
    "  Use this to find products based on a user's request.\n",
    "  The input must be a single string. For example: \"clip on reading light\"\n",
    "  \"\"\"\n",
    "  query = f\"\"\"\n",
    "    SELECT\n",
    "      productId,\n",
    "      product_name,\n",
    "      price,\n",
    "      rating,\n",
    "      review_count,\n",
    "      product_url\n",
    "    FROM hackathon2025.nimble.dbx_amazon_serp_daily\n",
    "    WHERE\n",
    "      product_name ILIKE '%{search_term}%'\n",
    "    LIMIT 5\n",
    "  \"\"\"\n",
    "  print(f\"Executing query: {query}\") # For debugging\n",
    "  df = spark.sql(query).toPandas()\n",
    "  return df.to_json(orient='records', indent=2)\n",
    "\n",
    "  w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "\n",
    "# The LLM is the \"brain\" of the agent\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=2048)\n",
    "\n",
    "# The Agent needs a list of tools it can use\n",
    "tools = [find_products_by_keyword]\n",
    "\n",
    "# This prompt template tells the agent how to reason and use tools\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Your process should be to first think of a few different, specific search terms based on the user's question.\n",
    "Then, use the `find_products_by_keyword` tool for each of those keywords, one at a time.\n",
    "After you have gathered all the product information from your searches, combine the results into a single, helpful summary for the user.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: After you find the products from all your searches, your final answer should summarize them and suggest that a good next step would be to use a web browsing tool to analyze the product pages for more detailed information.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent by combining the LLM, tools, and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask our agent to find a product related to accessibility\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"I'm looking for a tool to help my elderly parent open tight jars.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Final Answer ---\")\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6688380924212480,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "partner_data_quickstart",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
